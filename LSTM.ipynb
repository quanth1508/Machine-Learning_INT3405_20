{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-13T16:09:47.589945Z","iopub.execute_input":"2022-12-13T16:09:47.591272Z","iopub.status.idle":"2022-12-13T16:09:47.600399Z","shell.execute_reply.started":"2022-12-13T16:09:47.591199Z","shell.execute_reply":"2022-12-13T16:09:47.599262Z"},"trusted":true},"execution_count":180,"outputs":[{"name":"stdout","text":"/kaggle/input/int3405-sentiment-analysis-problem/test.csv\n/kaggle/input/int3405-sentiment-analysis-problem/full_train.csv\n","output_type":"stream"}]},{"cell_type":"code","source":" !pip install tensorflow==2.0","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:47.602599Z","iopub.execute_input":"2022-12-13T16:09:47.604006Z","iopub.status.idle":"2022-12-13T16:09:54.398791Z","shell.execute_reply.started":"2022-12-13T16:09:47.603968Z","shell.execute_reply":"2022-12-13T16:09:54.397239Z"},"trusted":true},"execution_count":181,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow==2.0 in /opt/conda/lib/python3.7/site-packages (2.0.0)\nRequirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0) (0.8.1)\nRequirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0) (1.12.1)\nRequirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0) (0.2.0)\nRequirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0) (1.19.5)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0) (1.1.0)\nRequirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0) (0.15.0)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0) (0.37.1)\nRequirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0) (2.0.2)\nRequirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0) (2.0.1)\nRequirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0) (1.32.0)\nRequirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0) (3.19.4)\nRequirement already satisfied: keras-applications>=1.0.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0) (1.0.8)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0) (1.15.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0) (3.3.0)\nRequirement already satisfied: gast==0.2.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0) (0.2.2)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0) (1.1.2)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==2.0) (2.10.0)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (59.8.0)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.2.2)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.4.6)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.35.0)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.28.1)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.3.7)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (4.2.4)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (4.8)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.2.7)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.3.1)\nRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (4.13.0)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2022.9.24)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.26.12)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=0.11.15->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.1.1)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.7.4.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.8.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.2.0)\n^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os\n!pip install pyvi\nimport numpy as np \nwith open('/kaggle/input/int3405-sentiment-analysis-problem/test.csv', encoding=\"utf8\") as f:\n    lines = f.readlines()\n    lines = \"\".join(lines)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:54.401034Z","iopub.execute_input":"2022-12-13T16:09:54.402749Z","iopub.status.idle":"2022-12-13T16:09:55.786215Z","shell.execute_reply.started":"2022-12-13T16:09:54.402693Z","shell.execute_reply":"2022-12-13T16:09:55.784541Z"},"trusted":true},"execution_count":182,"outputs":[{"name":"stdout","text":"^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"#Ignoring the warnings\nimport warnings\nwarnings.filterwarnings('ignore')\nimport seaborn as sns\n\n#Importing the required libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport re, string, unicodedata\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import GlobalMaxPooling1D\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import backend\nfrom tensorflow.keras import layers\nfrom sklearn.metrics import f1_score, confusion_matrix\nimport tensorflow as tf\nfrom pyvi import ViTokenizer\nfrom pyvi import ViUtils","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:55.788785Z","iopub.execute_input":"2022-12-13T16:09:55.789316Z","iopub.status.idle":"2022-12-13T16:09:55.801751Z","shell.execute_reply.started":"2022-12-13T16:09:55.789237Z","shell.execute_reply":"2022-12-13T16:09:55.799830Z"},"trusted":true},"execution_count":183,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"Tập dữ liệu gồm 2 trường:\n\n- Key: “comment”: các văn bản với nội dung đánh giá về quán ăn\n- Key: “rating”: là Label cho đoạn văn bản đó có nội dung tích cực hay tiêu cực.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"df1 = pd.read_csv('/kaggle/input/int3405-sentiment-analysis-problem/full_train.csv')\ndf1 = df1.dropna()\n\ndf1 = df1.drop(['Unnamed: 0','RevId','UserId','image_urls'], axis=1)\nX_train1 = list(df1['Comment'].values)\ny_train1 = list(df1['Rating'].values)\nprint(df1.shape)\ndf1.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:55.806441Z","iopub.execute_input":"2022-12-13T16:09:55.806897Z","iopub.status.idle":"2022-12-13T16:09:55.956123Z","shell.execute_reply.started":"2022-12-13T16:09:55.806863Z","shell.execute_reply":"2022-12-13T16:09:55.955450Z"},"trusted":true},"execution_count":184,"outputs":[{"name":"stdout","text":"(9070, 2)\n","output_type":"stream"},{"execution_count":184,"output_type":"execute_result","data":{"text/plain":"                                             Comment  Rating\n0  Xôi dẻo, đồ ăn đậm vị. Hộp xôi được lót lá trô...     1.0\n1  Gọi ship 1 xuất cari gà bánh naan và 3 miếng g...     0.0\n2  Thời tiết lạnh như này, cả nhà rủ nhau đến leg...     1.0\n3  Em có đọc review thấy mng bảo trà sữa nướng đề...     0.0\n4  Đồ ăn rất ngon, nhà hàng cũng rất đẹp, tất cả ...     1.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Comment</th>\n      <th>Rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Xôi dẻo, đồ ăn đậm vị. Hộp xôi được lót lá trô...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Gọi ship 1 xuất cari gà bánh naan và 3 miếng g...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Thời tiết lạnh như này, cả nhà rủ nhau đến leg...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Em có đọc review thấy mng bảo trà sữa nướng đề...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Đồ ăn rất ngon, nhà hàng cũng rất đẹp, tất cả ...</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Check DF","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# check for length train\nX_train = X_train1 #+ X_train2 + X_train3\nprint(len(X_train))\ny_train = y_train1 #+ y_train2 + y_train3\nprint(len(y_train))","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:55.959063Z","iopub.execute_input":"2022-12-13T16:09:55.959470Z","iopub.status.idle":"2022-12-13T16:09:55.965013Z","shell.execute_reply.started":"2022-12-13T16:09:55.959435Z","shell.execute_reply":"2022-12-13T16:09:55.964327Z"},"trusted":true},"execution_count":185,"outputs":[{"name":"stdout","text":"9070\n9070\n","output_type":"stream"}]},{"cell_type":"code","source":"sum(y_train)\nprint(sum(y_train) / len(y_train))","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:55.965743Z","iopub.execute_input":"2022-12-13T16:09:55.966013Z","iopub.status.idle":"2022-12-13T16:09:55.981807Z","shell.execute_reply.started":"2022-12-13T16:09:55.965983Z","shell.execute_reply":"2022-12-13T16:09:55.979645Z"},"trusted":true},"execution_count":186,"outputs":[{"name":"stdout","text":"0.7878721058434399\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check chart output data\nsns.countplot(y_train)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:55.983811Z","iopub.execute_input":"2022-12-13T16:09:55.984203Z","iopub.status.idle":"2022-12-13T16:09:56.049117Z","shell.execute_reply.started":"2022-12-13T16:09:55.984173Z","shell.execute_reply":"2022-12-13T16:09:56.045836Z"},"trusted":true},"execution_count":187,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/api/_v1/keras/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check chart output data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcountplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/seaborn/_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m             )\n\u001b[1;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mcountplot\u001b[0;34m(x, y, hue, data, order, hue_order, orient, color, palette, saturation, dodge, ax, **kwargs)\u001b[0m\n\u001b[1;32m   3600\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mci\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3601\u001b[0m         \u001b[0morient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3602\u001b[0;31m         \u001b[0merrcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdodge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3603\u001b[0m     )\n\u001b[1;32m   3604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, hue, data, order, hue_order, estimator, ci, n_boot, units, seed, orient, color, palette, saturation, errcolor, errwidth, capsize, dodge)\u001b[0m\n\u001b[1;32m   1583\u001b[0m         \u001b[0;34m\"\"\"Initialize the plotter.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m         self.establish_variables(x, y, hue, data, orient,\n\u001b[0;32m-> 1585\u001b[0;31m                                  order, hue_order, units)\n\u001b[0m\u001b[1;32m   1586\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestablish_colors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_statistic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mci\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mestablish_variables\u001b[0;34m(self, x, y, hue, data, orient, order, hue_order, units)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# Figure out the plotting orientation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             orient = infer_orient(\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_numeric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             )\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/seaborn/_core.py\u001b[0m in \u001b[0;36minfer_orient\u001b[0;34m(x, y, orient, require_numeric)\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m     \u001b[0mx_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mvariable_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1312\u001b[0;31m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mvariable_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0mnonnumeric_dv_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{} orientation requires numeric `{}` variable.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/seaborn/_core.py\u001b[0m in \u001b[0;36mvariable_type\u001b[0;34m(vector, boolean_type)\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m     \u001b[0;31m# Special-case all-na data, which is always \"numeric\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"numeric\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/dtypes/missing.py\u001b[0m in \u001b[0;36misna\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mName\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \"\"\"\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_isna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/dtypes/missing.py\u001b[0m in \u001b[0;36m_isna\u001b[0;34m(obj, inf_as_na)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_isna_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minf_as_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minf_as_na\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__array__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_isna_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minf_as_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minf_as_na\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"Text Preprocessing","metadata":{}},{"cell_type":"code","source":"def clean_text_support(text):\n    RE_EMOJI = re.compile('[\\U00010000-\\U0010ffff]', flags=re.UNICODE)\n    text = re.sub(r\"<.*?>\", \" \", text)\n    text = re.sub(r\"\\n\", \" \", text)\n    text = re.sub(r\"\\s{2,}\", \" \", text)\n    text = RE_EMOJI.sub(r'', text)\n    return text.strip().lower()","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:56.050832Z","iopub.status.idle":"2022-12-13T16:09:56.051417Z","shell.execute_reply.started":"2022-12-13T16:09:56.051144Z","shell.execute_reply":"2022-12-13T16:09:56.051168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_text(X):\n    processed = []\n    for text in X:\n        text = clean_text_support(text)\n        text = ViTokenizer.tokenize(text)\n        processed.append(text)\n    return processed","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:56.053699Z","iopub.status.idle":"2022-12-13T16:09:56.054114Z","shell.execute_reply.started":"2022-12-13T16:09:56.053923Z","shell.execute_reply":"2022-12-13T16:09:56.053941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_test = X_train[100]\nprint(text_test)\nprint('===')\nprint(X_train[333])","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:56.055353Z","iopub.status.idle":"2022-12-13T16:09:56.055687Z","shell.execute_reply.started":"2022-12-13T16:09:56.055527Z","shell.execute_reply":"2022-12-13T16:09:56.055543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_final = X_train","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:56.058040Z","iopub.status.idle":"2022-12-13T16:09:56.058594Z","shell.execute_reply.started":"2022-12-13T16:09:56.058368Z","shell.execute_reply":"2022-12-13T16:09:56.058392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X_train_final)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:56.060260Z","iopub.status.idle":"2022-12-13T16:09:56.060691Z","shell.execute_reply.started":"2022-12-13T16:09:56.060512Z","shell.execute_reply":"2022-12-13T16:09:56.060530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train_final[:2])\nprint(\"===\")\nprint(y_train[:2])","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:56.061987Z","iopub.status.idle":"2022-12-13T16:09:56.062367Z","shell.execute_reply.started":"2022-12-13T16:09:56.062172Z","shell.execute_reply":"2022-12-13T16:09:56.062189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Attention Layer\nfrom tensorflow.keras import initializers,regularizers,constraints\nfrom tensorflow.keras import backend as K\nclass AttentionWithContext(tf.keras.layers.Layer):\n    \"\"\"\n    Attention operation, with a context/query vector, for temporal data.\n    Supports Masking.\n    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n    \"Hierarchical Attention Networks for Document Classification\"\n    by using a context vector to assist the attention\n    # Input shape\n        3D tensor with shape: `(samples, steps, features)`.\n    # Output shape\n        2D tensor with shape: `(samples, features)`.\n    How to use:\n    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n    The dimensions are inferred based on the output shape of the RNN.\n    Note: The layer has been tested with Keras 2.0.6\n    Example:\n        model.add(LSTM(64, return_sequences=True))\n        model.add(AttentionWithContext())\n        # next add a Dense layer (for classification/regression) or whatever...\n    \"\"\"\n\n    def __init__(self, W_regularizer=None, u_regularizer=None, b_regularizer=None,\n                 W_constraint=None, u_constraint=None, b_constraint=None,\n                 bias=True, **kwargs):\n\n        self.supports_masking = True\n        self.init = initializers.get('glorot_uniform')\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.u_regularizer = regularizers.get(u_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n        self.u_constraint = constraints.get(u_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias = bias\n        super(AttentionWithContext, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 3\n\n        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_W'.format(self.name),\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        if self.bias:\n            self.b = self.add_weight(shape=(input_shape[-1],),\n                                     initializer='zero',\n                                     name='{}_b'.format(self.name),\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n\n        self.u = self.add_weight(shape=(input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_u'.format(self.name),\n                                 regularizer=self.u_regularizer,\n                                 constraint=self.u_constraint)\n\n        super(AttentionWithContext, self).build(input_shape)\n\n    def compute_mask(self, input, input_mask=None):\n        # do not pass the mask to the next layers\n        return None\n    def get_config(self):\n        config = super().get_config().copy()\n        config.update({\n            'W_regularizer': self.W_regularizer,\n            'u_regularizer': self.u_regularizer,\n            'b_regularizer': self.b_regularizer,\n            'W_constraint': self.W_constraint,\n            'u_constraint': self.u_constraint,\n            'b_constraint': self.b_constraint,\n            'bias': self.bias,\n            })\n        return config\n    def call(self, x, mask=None):\n        uit = dot_product(x, self.W)\n\n        if self.bias:\n            uit += self.b\n\n        uit = K.tanh(uit)\n        ait = dot_product(uit, self.u)\n\n        a = K.exp(ait)\n\n        # apply mask after the exp. will be re-normalized next\n        if mask is not None:\n            # Cast the mask to floatX to avoid float64 upcasting in theano\n            a *= K.cast(mask, K.floatx())\n\n        # in some cases especially in the early stages of training the sum may be almost zero\n        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n\n        a = K.expand_dims(a)\n        weighted_input = x * a\n        return K.sum(weighted_input, axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0], input_shape[-1]\n\ndef dot_product(x, kernel):\n    \"\"\"\n    Wrapper for dot product operation, in order to be compatible with both\n    Theano and Tensorflow\n    Args:\n        x (): input\n        kernel (): weights\n    Returns:\n    \"\"\"\n    if K.backend() == 'tensorflow':\n        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n    else:\n        return K.dot(x, kernel)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:56.063339Z","iopub.status.idle":"2022-12-13T16:09:56.064209Z","shell.execute_reply.started":"2022-12-13T16:09:56.063791Z","shell.execute_reply":"2022-12-13T16:09:56.063852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# some properties\nvocab_size = 60000\nmaxlen = 250\nencode_dim = 20\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X_train_final)\ntokenized_word_list = tokenizer.texts_to_sequences(X_train_final)\nX_train_padded = pad_sequences(tokenized_word_list, maxlen = maxlen, padding='post')","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:56.067598Z","iopub.status.idle":"2022-12-13T16:09:56.068002Z","shell.execute_reply.started":"2022-12-13T16:09:56.067827Z","shell.execute_reply":"2022-12-13T16:09:56.067844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#EarlyStopping and ModelCheckpoint\nes = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 5)\nmc = ModelCheckpoint('model_best.h5', monitor = 'val_loss', mode = 'min', verbose = 1, save_best_only = True)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:56.068768Z","iopub.status.idle":"2022-12-13T16:09:56.069110Z","shell.execute_reply.started":"2022-12-13T16:09:56.068955Z","shell.execute_reply":"2022-12-13T16:09:56.068971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Building model train","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import tensorflow_addons as tfa","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:56.071200Z","iopub.status.idle":"2022-12-13T16:09:56.071668Z","shell.execute_reply.started":"2022-12-13T16:09:56.071479Z","shell.execute_reply":"2022-12-13T16:09:56.071496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build model\ndef create_model():\n    model = Sequential()\n    embed = Embedding(input_dim = vocab_size, output_dim = 20, input_length = X_train_padded.shape[1]) \n    model.add(embed)\n    model.add(Dropout(0.4))\n    model.add(Bidirectional(LSTM(200, return_sequences = True)))\n    model.add(Dropout(0.3))\n    model.add(AttentionWithContext())\n    model.add(Dropout(0.3))\n    model.add(Dense(512))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dense(256))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dense(1, activation = 'sigmoid'))\n    model.summary()\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:56.072870Z","iopub.status.idle":"2022-12-13T16:09:56.073207Z","shell.execute_reply.started":"2022-12-13T16:09:56.073046Z","shell.execute_reply":"2022-12-13T16:09:56.073061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Traning model","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train_padded = np.asarray(X_train_padded)\ny_train = np.asarray(y_train)\nX_train_final2 = X_train_padded\ny_train_final2 = y_train\nweight = sum(y_train_final2) / y_train_final2.shape[0]","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:56.074453Z","iopub.status.idle":"2022-12-13T16:09:56.074797Z","shell.execute_reply.started":"2022-12-13T16:09:56.074621Z","shell.execute_reply":"2022-12-13T16:09:56.074637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#class weight\nweight_for_0 = (1 / (1-(weight))) * 0.5\nweight_for_1 = (1 / (weight))* 0.5\nclass_weight = {0: weight_for_0, 1: weight_for_1}","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:56.076028Z","iopub.status.idle":"2022-12-13T16:09:56.076400Z","shell.execute_reply.started":"2022-12-13T16:09:56.076195Z","shell.execute_reply":"2022-12-13T16:09:56.076213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 5)\nmc = ModelCheckpoint('model_best.h5', monitor = 'f1_score', mode = 'min', verbose = 1, save_best_only = True)\nbatch_size= 300\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='f1_score', factor=0.2,\n                              patience=3, min_lr=1e-5,verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:56.077238Z","iopub.status.idle":"2022-12-13T16:09:56.077628Z","shell.execute_reply.started":"2022-12-13T16:09:56.077451Z","shell.execute_reply":"2022-12-13T16:09:56.077468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tpu_strategy = tf.distribute.MirroredStrategy()","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:56.078786Z","iopub.status.idle":"2022-12-13T16:09:56.079088Z","shell.execute_reply.started":"2022-12-13T16:09:56.078938Z","shell.execute_reply":"2022-12-13T16:09:56.078953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# instantiating the model in the strategy scope creates the model on the TPU\nwith tpu_strategy.scope():\n    model = create_model() # define your model normally\n    optim =  tf.keras.optimizers.Adam(learning_rate=5e-4)\n\n    model.compile(optimizer='adam',\n                     loss='binary_crossentropy',\n                     metrics=['accuracy',\n                              tf.keras.metrics.Recall(),\n                              tfa.metrics.F1Score(num_classes=1,\n                                                 average='micro')\n                             ]\n             )","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:56.079934Z","iopub.status.idle":"2022-12-13T16:09:56.080235Z","shell.execute_reply.started":"2022-12-13T16:09:56.080086Z","shell.execute_reply":"2022-12-13T16:09:56.080101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X_train_final2)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:56.081624Z","iopub.status.idle":"2022-12-13T16:09:56.082444Z","shell.execute_reply.started":"2022-12-13T16:09:56.082242Z","shell.execute_reply":"2022-12-13T16:09:56.082264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x, train_y = np.array(X_train_final2), np.array(y_train_final2)\ntrain_data = tf.data.Dataset.from_tensor_slices((train_x, train_y))","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:56.083481Z","iopub.status.idle":"2022-12-13T16:09:56.083837Z","shell.execute_reply.started":"2022-12-13T16:09:56.083646Z","shell.execute_reply":"2022-12-13T16:09:56.083674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 512 * tpu_strategy.num_replicas_in_sync\n\ntrain_data = train_data.batch(batch_size)\n# val_data = val_data.batch(batch_size)\n# Disable AutoShard.\noptions = tf.data.Options()\noptions.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\ntrain_data = train_data.with_options(options)\n# val_data = val_data.with_options(options)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:56.084580Z","iopub.status.idle":"2022-12-13T16:09:56.084885Z","shell.execute_reply.started":"2022-12-13T16:09:56.084738Z","shell.execute_reply":"2022-12-13T16:09:56.084753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fit model\nmodel.fit(train_data ,\n          epochs = 15, batch_size = batch_size, verbose = 1,\n          callbacks = [reduce_lr, es,mc],class_weight=class_weight)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:56.086836Z","iopub.status.idle":"2022-12-13T16:09:56.087186Z","shell.execute_reply.started":"2022-12-13T16:09:56.087014Z","shell.execute_reply":"2022-12-13T16:09:56.087029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/int3405-sentiment-analysis-problem/test.csv')\ndata_test = pd.DataFrame({'input':df['Comment'],'id':df[\"RevId\"]})\nX_test = list(data_test['input'].values)\n\ndef clean_text_test(X):\n    idx = 0\n    y_train = []\n    processed = []\n    for text in X:\n        text = str(text)\n        text = clean_text_support(text)\n        input_text_pre_accent = ViTokenizer.tokenize(text)\n        processed.append(input_text_pre_accent)\n    return processed\n# X_test = list()\nX_test_final = clean_text_test(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:56.088572Z","iopub.status.idle":"2022-12-13T16:09:56.088901Z","shell.execute_reply.started":"2022-12-13T16:09:56.088746Z","shell.execute_reply":"2022-12-13T16:09:56.088762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_submission['Rating'].sum() / len(my_submission['Rating'])","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:56.092348Z","iopub.status.idle":"2022-12-13T16:09:56.092703Z","shell.execute_reply.started":"2022-12-13T16:09:56.092534Z","shell.execute_reply":"2022-12-13T16:09:56.092550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_submission = pd.DataFrame({'RevId': np.array(df[\"RevId\"]).reshape(5103), 'Rating': np.array(y_pred).reshape(5103)})\nmy_submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T16:09:56.093702Z","iopub.status.idle":"2022-12-13T16:09:56.094008Z","shell.execute_reply.started":"2022-12-13T16:09:56.093856Z","shell.execute_reply":"2022-12-13T16:09:56.093871Z"},"trusted":true},"execution_count":null,"outputs":[]}]}